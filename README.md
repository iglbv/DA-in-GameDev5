# АНАЛИЗ ДАННЫХ И ИСКУССТВЕННЫЙ ИНТЕЛЛЕКТ [in GameDev]
Отчет по лабораторной работе #5 выполнил(а):
- Голубев Илья Дмитриевич
- РИ-220934

| Задание | Выполнение | Баллы |
| ------ | ------ | ------ |
| Задание 1 | * | 60 |
| Задание 2 | * | 20 |
| Задание 3 | * | 20 |

знак "*" - задание выполнено; знак "#" - задание не выполнено;

Работу проверили:

-

## Цель работы
Познакомиться с программными средствами для создания системы машинного обучения и ее интеграции в Unity.

## Задание 1
### Найдите внутри C# скрипта “коэффициент корреляции” и сделать выводы о том, как он влияет на обучение модели.
Ход работы:
В скрипте RollerAgent находится метод, в котором используется коэффициент корреляции: 

![image](https://github.com/iglbv/DA-in-GameDev5/assets/130669110/7a50e5bf-ce44-4f53-8f82-0730241a81d5)

Коэффициент определяет, на каком расстоянии должны находиться объект и цель, чтобы получить награду. Если мы уменьшаем коэффициент, то объекту будет сложнее обучаться, так как объект должен будет находиться ближе к цели. А если увеличиваем, то объекту будет легче обучаться, так как он будет получать награду находясь дальше от цели.


## Задание 2
### Изменить параметры файла yaml-агента и определить какие параметры и как влияют на обучение модели. Привести описание не менее трех параметров.

Ход работы:
1. max_steps - уменьшим на 500000 шагов. Это общее количество шагов, которые необходимо выполнить в среде перед завершением процесса обучения. Чем больше значение, тем модель лучше обучается на "своем опыте". Можно понизить, чтобы увеличить скорость рендеринга.
2. num_epoch - увеличим на 5. Это количество проходов(эпох обучения). При увеличении модель будет лучше обучаться, но увеличиться время рендеринга.
3. summary_freq - увеличим на 50000. Это количество опыта, который необходимо собрать перед созданием и отображением статистики обучения. Чем выше опыт, тем лучше определяется степень детализации графиков в Tensorboard. 

![image](https://github.com/iglbv/DA-in-GameDev5/assets/130669110/c1d563e3-33b6-428e-8eb0-d95b368fcbfb)


## Задание 3
### Приведите примеры, для каких игровых задачи и ситуаций могут использоваться примеры 1 и 2 с ML-Agent’ом. В каких случаях проще использовать ML-агент, а не писать программную реализацию решения? 

Ход работы:

1. ML-Agent может использоваться для примитивных поведений NPC в игре. Например, их передвижение по игровому миру, чтобы они шли(ехали) ровно по нужной дороге, не врезались в объекты и знали как обойти(объехать) препятствия.
2. ML-Agent может быть использован например для того, чтобы NPC в шутере учился экономить свои боеприпасы. Если у него полный магазин, то он щедро стреляет в свою цель, но если его магазин начинает заканчиваться, NPC начинает стрелять реже и точнее, экономить свои ресурсы.

Использовать ML Агент нужно в тех случаях, где игровая ситуация постоянно меняется(от течения времени или поведения игрока). Программная реализация слишком ненадежна, и может неадекватно реагировать на изменения игровой ситуации. Программная реализация совсем не адаптивна, в отличие от ML Агента.

## Выводы

Мы познакомились с программными средствами для создания системы машинного обучения и ее интеграции в Unity. Изучили как подключать и работать с ML агентом. Изменили torch параметры и проследили как это влияет на обучение модели.
